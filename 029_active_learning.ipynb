{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6f8c9a-d2c7-473f-b909-c95c6ed6eb87",
   "metadata": {},
   "source": [
    "# Criteria\n",
    "\n",
    "## 1. Selected pairs of images with similar scores. \n",
    "\n",
    "    To get more detailed rank info. Because the scores are assigned by our scoring model, this might be accurate when predicting the selection of images with large score delta. But for images with small score delta, it performs badly.\n",
    "## 2. Selected pairs within similar images.\n",
    "\n",
    "    Currently,  annotatorâ€™s selection is strongly affected by the image topic or style. I.e., the annotator may alway choose Nintendo Mario style images, therefore, the scoring models will assign high scores to them. \n",
    "    This policy will force the annotator to focus on the image quality and may help us improve generation.\n",
    "\n",
    "# Implement\n",
    "\n",
    "## 1. Function: get_candidate_pairs_within_category\n",
    "\n",
    "I will first provide a general function to get candidate pairs within category\n",
    "\n",
    "Input:\n",
    "- categories: np.ndarray[int], shape is (N,)\n",
    "- max_pairs: int, max selecting pairs. \n",
    "- max_pairs should 0 < max_pairs < (N / n_categories) ** 2.\n",
    "    we will attempt to select (max_pairs / n_categories) pairs within each category.\n",
    "    \n",
    "Output:\n",
    "\n",
    "pairs: list[(index, index)], seleted pairs, index of input categories.\n",
    "\n",
    "\n",
    "## 2. Function: get_candidate_pairs_by_score\n",
    "\n",
    "I use 2 way to binning scores to categories:\n",
    "By fixed step bins\n",
    "By quantities\n",
    "\t\n",
    "\tI will provide a function to get candidate pairs with similar scores\n",
    "\n",
    "Input:\n",
    "- scores: np.ndarray[float], shape is (N,)\n",
    "- max_pairs: int, max selecting pairs. \n",
    "- n_bins: int, number of categories to be divided\n",
    "- use_quantities: bool, to use quantities or fixed step bins\n",
    "\n",
    "Output:\n",
    "\n",
    "pairs: list[(index, index)], seleted pairs, index of input scores.\n",
    "\t\n",
    "\n",
    "## 3. Function: get_candidate_pairs_by_embedding\n",
    "\t\n",
    "I use kmeans to divide images into categories of clusters.\n",
    "\n",
    "Input:\n",
    "- embeddings: np.ndarray, shape is (N, 768)\n",
    "- max_pairs: int, max selecting pairs. \n",
    "- n_clusters: int, number of categories to be divided\n",
    "\n",
    "Output:\n",
    "\n",
    "pairs: list[(index, index)], seleted pairs, index of input embeddings.\n",
    "\n",
    "These 2 criteria can be used with existing filters, we can filter images with score / variance / date, and pass the uuids and corresponding scores or embeddings to the function, and get candidate pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3fa0b4-d4cb-44fa-b8d9-5bc3d0d26bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.pairs import get_candidate_pairs_by_score, get_candidate_pairs_by_embedding, embedding_to_category, get_candidate_pairs_within_category\n",
    "from script.samples import get_min_distance_to_representative_samples\n",
    "from utils import get_score_from_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4621601d-a939-4ab3-bbfa-bf29eddc439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '../kcg-ml-image-pipeline/output/dataset/'\n",
    "\n",
    "DATASETs = [\n",
    "    'environmental', \n",
    "    'character', \n",
    "    'icons', \n",
    "    'mech', \n",
    "    'waifu',\n",
    "    'propaganda-poster'\n",
    "]\n",
    "\n",
    "SAVE_DIR = './result/1130/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640fd9da-7e0e-4cc1-a1cb-753a7854a0c2",
   "metadata": {},
   "source": [
    "# save image info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a347f4e3-3e96-4cd5-a0ed-55e2310c05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_info(dataset_name):\n",
    "\n",
    "    #\n",
    "\n",
    "    emb_path = os.path.join('./data', dataset_name, 'clip_vision_emb.npz')\n",
    "    \n",
    "    npz = np.load(emb_path, allow_pickle=True)\n",
    "    \n",
    "    samples = npz['image_embeds'].astype('float32')\n",
    "    \n",
    "    file_paths = npz['file_paths']\n",
    "    file_paths = [os.path.splitext(file_path.split('_')[0])[0] for file_path in file_paths]\n",
    "    path_to_index = {file_path: i for i, file_path in enumerate(file_paths)}\n",
    "\n",
    "    #\n",
    "    \n",
    "    pmt_path = os.path.join('./data', dataset_name, 'prompt.json')\n",
    "    \n",
    "    prompts = json.load(open(pmt_path))\n",
    "    \n",
    "    path_to_hash = {j['file_path'].split('_')[0]:i for i, j in prompts.items()}\n",
    "    path_to_uuid = {j['file_path'].split('_')[0]: j['job_uuid'] for i, j in prompts.items()}\n",
    "    # uuid_to_path = {j: i for i, j in path_to_uuid.items()}\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        zip(file_paths, map(path_to_hash.get, file_paths), map(path_to_uuid.get, file_paths)), \n",
    "        columns=['file_path', 'file_hash', 'job_uuid']\n",
    "    )\n",
    "    \n",
    "    # score\n",
    "    \n",
    "    vision_weight_path = os.path.join('./weight/004', dataset_name, 'clip_vision.pt')\n",
    "    \n",
    "    vision_model = torch.nn.Linear(samples.shape[-1], 1, bias=True).cuda().eval()\n",
    "    vision_model.load_state_dict(torch.load(vision_weight_path))\n",
    "\n",
    "    score = get_score_from_embs(samples, vision_model, batch_size=1024)\n",
    "    df['sigma_score'] = (score - score.mean()) / score.std()\n",
    "    \n",
    "    # distance\n",
    "    \n",
    "    representative_names = json.load(open(os.path.join('./data', dataset_name, 'representative.json')))['representative']\n",
    "    representative_indices = list(map(path_to_index.get, representative_names))\n",
    "    representative_samples = samples[representative_indices]\n",
    "    \n",
    "    df['min_distance_to_representative_samples'] = get_min_distance_to_representative_samples(samples, representative_samples, distance_type='cosine')\n",
    "\n",
    "    # \n",
    "    \n",
    "    for n_clusters in [10, 100]:\n",
    "        if n_clusters > samples.shape[0] / 100:\n",
    "            break\n",
    "        df[f'category_{n_clusters}'] = embedding_to_category(embeddings=samples, n_clusters=n_clusters)\n",
    "\n",
    "    #\n",
    "\n",
    "    os.makedirs(os.path.join(SAVE_DIR, dataset_name), exist_ok=True)\n",
    "    \n",
    "    df.to_csv(os.path.join(SAVE_DIR, dataset_name, 'image_info.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e1d939-7058-402a-9571-1be57498d3db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset_name in DATASETs:\n",
    "    save_image_info(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c9117-a896-4900-bc47-21c77723be86",
   "metadata": {},
   "source": [
    "# save_rank_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a58a64-4bdc-4d0e-ae66-08037f90916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_uuid_pairs(df, pairs):\n",
    "    \n",
    "    indices_1, indices_2 = zip(*pairs)\n",
    "\n",
    "    job_uuid_1s = df['job_uuid'].iloc[list(indices_1)]\n",
    "    job_uuid_2s = df['job_uuid'].iloc[list(indices_2)]\n",
    "    \n",
    "    return [((job_uuid_1, job_uuid_2) if job_uuid_1 < job_uuid_2 else (job_uuid_2, job_uuid_1)) for job_uuid_1, job_uuid_2 in zip(job_uuid_1s, job_uuid_1s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e5d603-9b31-4f55-b100-307842c375f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rank_queue(dataset_name):\n",
    "\n",
    "    pmt_path = os.path.join('./data', dataset_name, 'prompt.json')\n",
    "    \n",
    "    prompts = json.load(open(pmt_path))\n",
    "    \n",
    "    ranked_pairs = set()\n",
    "    for fname in tqdm(os.listdir(os.path.join(ROOT, 'ranking', dataset_name)), leave=False):\n",
    "        js = json.load(open(os.path.join(ROOT, 'ranking', dataset_name, fname)))\n",
    "        \n",
    "        file_hash_1 = js['image_1_metadata']['file_hash']\n",
    "        file_hash_2 = js['image_2_metadata']['file_hash']\n",
    "    \n",
    "        try:\n",
    "            job_uuids_1 = prompts[file_hash_1]['job_uuid']\n",
    "            job_uuids_2 = prompts[file_hash_2]['job_uuid']\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        ranked_pairs.add((job_uuids_1, job_uuids_2))\n",
    "        ranked_pairs.add((job_uuids_2, job_uuids_1))\n",
    "    \n",
    "    #\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(SAVE_DIR, dataset_name, 'image_info.csv')).dropna()\n",
    "    df.query('sigma_score > .75', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #\n",
    "    \n",
    "    result = df.query(f'min_distance_to_representative_samples > 0.25')[['job_uuid']].copy()\n",
    "    result['policy'] = 'far_distance_to_ranked_images'\n",
    "    result.to_csv(os.path.join(SAVE_DIR, dataset_name, 'images.csv') , index=False)\n",
    "    \n",
    "    #\n",
    "    \n",
    "    results = list()\n",
    "    \n",
    "    for n_bins in [10, 100]:\n",
    "        \n",
    "        pairs = get_candidate_pairs_by_score(df['sigma_score'].values, max_pairs=1000, n_bins=n_bins, use_quantiles=True)\n",
    "        \n",
    "        pairs = get_job_uuid_pairs(df, pairs)\n",
    "        results.extend([pair + (f'same_sigma_score_bin_{n_bins}',) for pair in pairs if pair not in ranked_pairs])\n",
    "    \n",
    "    for n_clusters in [10, 100]:\n",
    "        \n",
    "        if f'category_{n_clusters}' not in df.columns:\n",
    "            break\n",
    "            \n",
    "        pairs = get_candidate_pairs_within_category(df[f'category_{n_clusters}'].values, max_pairs=1000)\n",
    "        \n",
    "        pairs = get_job_uuid_pairs(df, pairs)\n",
    "        results.extend([pair + (f'same_embedding_cluster_{n_bins}',) for pair in pairs if pair not in ranked_pairs])\n",
    "        \n",
    "    results = pd.DataFrame(results, columns=['job_uuid_1', 'job_uuid_2', 'policy'])\n",
    "    results.drop_duplicates(['job_uuid_1', 'job_uuid_2'], keep='first', inplace=True)\n",
    "    results.to_csv(os.path.join(SAVE_DIR, dataset_name, 'pairs.csv') , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0da16f-8af6-4d32-bbce-ed1fcbff0543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/529 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/798 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset_name in DATASETs:\n",
    "    save_rank_queue(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88310337-5f23-4cee-8886-57a15d0412e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# select images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "720fe0e8-1148-48a3-b34f-84834324e440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09ae4c7a-ba22-470c-9610-ca3c467a4596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(npz['file_paths'], labels), columns=['file_path', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "56863736-1108-44c5-b3c7-bfddfb6bf1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_dir = './image_clustering_clip_vision_kmeans'\n",
    "\n",
    "for c, g in df.groupby('label'):\n",
    "    \n",
    "    os.makedirs(os.path.join(target_dir, f'{c}'), exist_ok=True)\n",
    "    \n",
    "    if g.shape[0] < 5:\n",
    "        continue\n",
    "    \n",
    "    selected = np.random.choice(g['file_path'], 5, False)\n",
    "    \n",
    "    for file_path in selected:\n",
    "        file_path = os.path.join('../kcg-ml-image-pipeline/output/dataset/image/', file_path.split('_')[0] + '.jpg')\n",
    "        os.system(f'cp {file_path} {target_dir}/{c}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071b0ba-e82d-4b0c-91e9-8d2211df33d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3278ce8-1c66-49ce-98e6-5ea43bbc6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from minio import Minio\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c51ed09e-07d4-4cd8-b589-322ccdded2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class API:\n",
    "\n",
    "    def __init__(self, api_url: str, display: bool = False, **kwargs):\n",
    "        self.api_url = api_url\n",
    "        self.display = display\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def get(self, url: str, data: dict = None, return_content: bool = True, **kwargs):\n",
    "        \n",
    "        kwargs_ = dict(**self.kwargs)\n",
    "        kwargs_.update(kwargs)\n",
    "        if data is not None:\n",
    "            kwargs_['params'] = data\n",
    "\n",
    "        response = requests.get(f'{self.api_url}/{url}', **kwargs_)\n",
    "\n",
    "        if return_content:\n",
    "            if response.status_code != 200:\n",
    "                raise Exception(f'{url} responded status_code {status_code}')\n",
    "            return response.content\n",
    "        return response\n",
    "        \n",
    "    def post(self, data, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def get_rank_list(self, dataset: str):\n",
    "\n",
    "        content = self.get('datasets/rank/list', data={'dataset': dataset})\n",
    "\n",
    "        return json.loads(content)\n",
    "\n",
    "    # def get_rank_infos(self, dataset: str, filenames: list):\n",
    "\n",
    "    #     infos = list()\n",
    "\n",
    "    #     for filename in tqdm(filenames, leave=False, disable=not self.display):\n",
    "\n",
    "    #         info = None\n",
    "            \n",
    "    #         try:\n",
    "                \n",
    "    #             content = self.get(\n",
    "    #                 'datasets/rank/read', \n",
    "    #                 data={\n",
    "    #                     'dataset': dataset,\n",
    "    #                     'filename': filename\n",
    "    #                 },\n",
    "    #                 return_content=False\n",
    "    #             )\n",
    "\n",
    "    #             if content.status_code == 200:\n",
    "    #                 info = json.loads(content)\n",
    "            \n",
    "    #         except KeyboardInterrupt:\n",
    "    #             break\n",
    "    #         except:\n",
    "    #             pass\n",
    "\n",
    "    #         infos.append(info)\n",
    "\n",
    "    #     return infos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b9d60c3-a81a-437e-8e38-164d0302c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'http://123.176.98.90:8764'\n",
    "dataset = 'mech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "120cfef5-ce68-4dbd-b348-9e19bb7c921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API(api_url, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb11299-f74b-4134-a7bf-ab3f498de2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_result_file_paths = api.get_rank_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd6fddd2-0576-42c1-9014-c01cef8ebb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_result_file_names = [os.path.split(file_path)[-1] for file_path in rank_result_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc462f4-53b0-4e28-979d-9e9b31d63fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infos = api.get_rank_infos(dataset, rank_result_file_names)\n",
    "infos = list(tqdm(\n",
    "    map(lambda file_name: get_file_from_minio(client, bucket_name, file_name), rank_result_file_paths), \n",
    "    leave=False, total=len(rank_result_file_paths)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c4d2fa4-aec1-482e-ad8c-074cd1cf8548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mech/data/ranking/aggregate/2023-10-23-15-50-38-mert.json'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_result_file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b01b523-dba7-4950-923f-021519be6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_ADDRESS = \"123.176.98.90:9000\"\n",
    "access_key = \"GXvqLWtthELCaROPITOG\"\n",
    "secret_key = \"DmlKgey5u0DnMHP30Vg7rkLT0NNbNIGaM8IwPckD\"\n",
    "bucket_name = 'datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6ecf750-3a3b-4ea7-af55-6e6d02d9dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_minio(minio_addr, access_key, secret_key):\n",
    "    # Initialize the MinIO client\n",
    "    client = Minio(minio_addr, access_key, secret_key, secure=False)\n",
    "\n",
    "    #Check server status\n",
    "    try:\n",
    "        response = requests.get(\"http://\" + minio_addr + \"/minio/health/live\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Connected to MinIO server.\")\n",
    "        else:\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        return None\n",
    "    \n",
    "    return client\n",
    "\n",
    "def get_file_from_minio(client, bucket_name, file_name):\n",
    "    try:\n",
    "        # Get object data\n",
    "        data = client.get_object(bucket_name, file_name)\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45e3011e-b999-4d0e-9a41-6e112b43afd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MinIO server.\n"
     ]
    }
   ],
   "source": [
    "client = connect_to_minio(MINIO_ADDRESS, access_key, secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5ea26-240b-43e2-ac60-11163ab69786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c744c2df-88d4-4875-bd0d-eb8d46a53ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mdir\u001b[39m(\u001b[43mclient\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "client.get_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a18e7c69-388e-44a9-b35e-08a43a47087e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objects = client.list_objects(bucket_name, dataset_name, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b991575-8840-4177-9025-dd976a42e6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9768442bfd0465ab128320699721d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = list(tqdm(objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09eb77b-1cfa-4cc1-8c02-51f413cc0d24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcddff4c691434eafcdeb127d636b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1960419 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for obj in tqdm(objects):\n",
    "    \n",
    "    object_name = obj.object_name\n",
    "    \n",
    "    # if not object_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "    #     continue\n",
    "    # out_path = os.path.join(ROOT, 'image', object_name)\n",
    "    \n",
    "    # if not object_name.lower().endswith('_clip.msgpack'):\n",
    "    #     continue\n",
    "    # out_path = os.path.join(ROOT, 'clip', object_name)\n",
    "\n",
    "    if object_name.lower().endswith('_clip.msgpack'):\n",
    "        out_path = os.path.join(ROOT, 'clip', object_name)\n",
    "    elif object_name.lower().endswith('_data.msgpack'):\n",
    "        out_path = os.path.join(ROOT, 'data', object_name)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    if os.path.exists(out_path):\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        client.fget_object(bucket_name, object_name, out_path)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk",
   "language": "python",
   "name": "kk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
