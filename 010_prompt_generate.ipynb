{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178e3cd4-878a-4f31-9b2a-8688168b895e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,2,3,4,5,7'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "BATCH_SIZE = 56\n",
    "MAX_PROMPT_LENGTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e4e95d-7c88-4be8-aaa2-cb6c7a2cddfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9091b1-5937-4474-986a-ce2863ba334b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prompt_datasets import PromptDataset, MultipleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad167e05-c61e-483c-b491-2f779d345e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL_PATH = 'crumb/bloom-560m-RLHF-SD2-prompter'\n",
    "# MODEL_PATH = 'weight/bloom-560m-shuffle'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "# tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7c9b29-9947-4d3c-9666-02c8d7c63a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_PATH = 'FredZhang7/distilgpt2-stable-diffusion-v2'\n",
    "MODEL_PATH = 'weight/distilgpt2-long/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "tokenizer.pad_token = '\\x7f'\n",
    "tokenizer.pad_token_id = tokenizer('\\x7f').input_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec9ad5-1e5c-4d53-9b27-391c130b201b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## extend dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f125c01a-7031-4ce3-bfe8-e8ea3605d330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_file_paths = [\n",
    "    # '../dataset/nonredundant-laion2B_aesthetic.tsv'\n",
    "    # '../dataset/nonredundant-midjourney_prompts.tsv'\n",
    "    '../dataset/nonredundant-dalle_captions.tsv',\n",
    "    '../dataset/nonredundant-dalle_chatgpt_prompts.tsv',\n",
    "    '../dataset/nonredundant-dalle_discord_prompts.tsv',\n",
    "    '../dataset/nonredundant-midjourney_prompts-paired.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a07b1c71-12ad-4a00-8810-d3be6336a176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = list()\n",
    "\n",
    "for file_path in prompt_file_paths:\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    prompts.append(df)\n",
    "    \n",
    "prompts = pd.concat(prompts, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e06f124-4788-4b43-8559-f0c6f324ecf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f3f777cbe04baca44a2b1396ddb290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1321952 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extend_dataset = PromptDataset(prompts, tokenizer, p_shuffle=0.25, max_shuffle=2, p_cut=0.1, max_prompt_length=MAX_PROMPT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad509ead-f82b-47fb-9cec-1a21623a863b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# samples = list()\n",
    "# lengths = list()\n",
    "# for tokens, is_positive in tqdm(extend_dataset.samples):\n",
    "#     length = len(tokens)\n",
    "    \n",
    "#     if length < 25:\n",
    "#         p = ((length / 25) ** 3) * 0.2\n",
    "#     elif length < 50:\n",
    "#         p = ((length - 25) / 25) ** 0.75\n",
    "\n",
    "#     # if length < 25:\n",
    "#     #     p = ((length / 25) ** 2) * 0.1\n",
    "#     # elif length < 50:\n",
    "#     #     p = ((length - 25) / 25) ** 0.5\n",
    "        \n",
    "#     else:\n",
    "#         p = 1\n",
    "#     if np.random.rand() < p:\n",
    "#         lengths.append(length)\n",
    "#         samples.append((tokens, is_positive))\n",
    "        \n",
    "# len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3197f97-5786-48c4-8a35-90dfd178745c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sampled_aesthetic = np.array([i[0].numpy().astype('int32') for i in samples], dtype='object')\n",
    "# np.save('sampled_aesthetic.npy', sampled_aesthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c431aa7-3389-4b9c-be06-16382eccc0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sampled_midjourney = np.array([i[0].numpy().astype('int32') for i in samples], dtype='object')\n",
    "# np.save('sampled_midjourney.npy', sampled_midjourney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b45964-358b-4407-a42a-2c931f06fb24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extend_dataset.samples += [(torch.tensor(i), True) for i in np.load('sampled_aesthetic-extend.npy', allow_pickle=True) if len(i) < extend_dataset.max_prompt_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d2b2b1-3a4e-4c07-883a-4734c65431df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extend_dataset.samples += [(torch.tensor(i), True) for i in np.load('sampled_midjourney-extend.npy', allow_pickle=True) if len(i) < extend_dataset.max_prompt_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0adc9e-9691-4cb6-b27e-70e02c349b88",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bddd6de-7170-4a92-9c4c-241bfd7b88eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_file_paths = [\n",
    "    # '../dataset/nonredundant-civitai_prompts.tsv',\n",
    "    # '../dataset/nonredundant-discord_prompts.tsv',\n",
    "    '../dataset/nonredundant-lexica_prompts-train.tsv',\n",
    "    '../dataset/nonredundant-lexica_prompts-eval.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3183d5-750b-4d97-9aaa-5d69473a3712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = list()\n",
    "\n",
    "for file_path in prompt_file_paths:\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    prompts.append(df)\n",
    "    \n",
    "prompts = pd.concat(prompts, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27cf991-bc5d-4891-b9fe-eb2a87723462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8383f419b592419fa4023683bb0eb07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67789 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = PromptDataset(prompts, tokenizer, p_shuffle=0.5, max_shuffle=3, p_cut=0.2, max_prompt_length=MAX_PROMPT_LENGTH, overflow_method='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c409b-bb8d-4d74-a1b7-17d38c32d912",
   "metadata": {},
   "source": [
    "## long dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5880b272-dec5-4330-b420-e446f2a153d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_file_paths = [\n",
    "    '../dataset/long-laion2B-en-aesthetic.tsv',\n",
    "    '../dataset/long-midjourney_prompts.tsv',\n",
    "    '../dataset/long-midjourney_prompts-2.tsv',\n",
    "    '../dataset/nonredundant-leonardo_prompts.tsv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a30dbbc8-40e6-4afa-9d11-2aee1b624f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = list()\n",
    "\n",
    "for file_path in prompt_file_paths:\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    prompts.append(df)\n",
    "    \n",
    "prompts = pd.concat(prompts, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbb224f4-d406-4c63-8ef6-4844a56636cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bae837bfb14bc3acba2b2166411221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/981564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_dataset = PromptDataset(prompts, tokenizer, p_shuffle=0.25, max_shuffle=1, p_cut=0.2, max_prompt_length=MAX_PROMPT_LENGTH, overflow_method='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12cec78-b329-4f02-97e7-908e5321c3b8",
   "metadata": {},
   "source": [
    "## merge & split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eb3cbfe-bfbb-4b98-a644-108072576c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3549578, 11391945, 1536356, 11391945)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = MultipleDataset([dataset, extend_dataset, long_dataset], probabilities=[0.6, 0.2, 0.2])\n",
    "len(dataset), len(extend_dataset), len(long_dataset), len(merged_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b4f2348-5217-4b3f-a826-845c34ace1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len_val_set = int(len(merged_dataset) * 0.001)\n",
    "train_set, val_set = torch.utils.data.random_split(merged_dataset, (len(merged_dataset) - len_val_set, len_val_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcbd9c-1f1c-4400-80bc-a5b97b369a39",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "339326d2-0be1-4824-82f6-2fedb7a2d4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd464e00-7428-40af-8a1e-fc347c4026a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "781e2f71-0c3e-4d81-bdbb-f6817bc181e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"GPT2-extend\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_steps=1_000,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=2e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    \n",
    "    push_to_hub=False,\n",
    "    dataloader_drop_last=True,\n",
    "    # dataloader_num_workers=8,\n",
    "    # group_by_length=True,\n",
    "    \n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1_000,\n",
    "    do_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3475dae8-26ed-45b5-8806-7fd8b65c3f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=dataset.tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df910c-9723-4aef-95b3-d3fb6a9b9407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sunjie/kk-digital/kcg-ml-image-pipeline/venv/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/sunjie/kk-digital/kcg-ml-image-pipeline/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5510' max='67740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5510/67740 1:19:27 < 14:57:39, 1.16 it/s, Epoch 0.16/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.032800</td>\n",
       "      <td>1.975594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.133900</td>\n",
       "      <td>2.015074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.153400</td>\n",
       "      <td>2.017757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.154400</td>\n",
       "      <td>2.046337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.159700</td>\n",
       "      <td>2.036520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sunjie/kk-digital/kcg-ml-image-pipeline/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dff6d3-7e34-47a6-aa90-c7a67e9cfaae",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b519461-875a-44a5-a9d9-a7c011fe55bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('weight/distilgpt2-long/tokenizer_config.json',\n",
       " 'weight/distilgpt2-long/special_tokens_map.json',\n",
       " 'weight/distilgpt2-long/vocab.json',\n",
       " 'weight/distilgpt2-long/merges.txt',\n",
       " 'weight/distilgpt2-long/added_tokens.json',\n",
       " 'weight/distilgpt2-long/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tokenizer.save_pretrained('weight/distilgpt2-long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "896c43d0-89fd-4c46-823c-5627fc3c7ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('weight/distilgpt2-long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef66db-0d4f-4818-80ae-19e45870fc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk",
   "language": "python",
   "name": "kk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
