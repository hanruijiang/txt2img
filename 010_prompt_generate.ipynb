{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178e3cd4-878a-4f31-9b2a-8688168b895e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3,0,1,2,4,5'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "BATCH_SIZE = 96\n",
    "\n",
    "MIN_LONG_PROMPT_TOKEN_LENGTH = 50\n",
    "MAX_PROMPT_TOKEN_LENGTH = 150\n",
    "MAX_PROMPT_LENGTH = 1500\n",
    "MAX_TAG_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e4e95d-7c88-4be8-aaa2-cb6c7a2cddfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9091b1-5937-4474-986a-ce2863ba334b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prompt_datasets import PromptDataset, MultipleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad167e05-c61e-483c-b491-2f779d345e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL_PATH = 'crumb/bloom-560m-RLHF-SD2-prompter'\n",
    "# MODEL_PATH = 'weight/bloom-560m-shuffle'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "# tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7c9b29-9947-4d3c-9666-02c8d7c63a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_PATH = 'FredZhang7/distilgpt2-stable-diffusion-v2'\n",
    "MODEL_PATH = 'weight/distilgpt2-extend/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "tokenizer.pad_token = '\\x7f'\n",
    "tokenizer.pad_token_id = tokenizer('\\x7f').input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91d6912-c348-4abb-925e-76d0a3438e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \n",
    "    df.fillna('', inplace=True)\n",
    "    \n",
    "    df['negative_prompt'] = [', '.join([j.strip() for j in i.split(',') if 'negative' not in j]) for i in df['negative_prompt']]\n",
    "    \n",
    "    df['positive_length'] = df['positive_prompt'].str.len()\n",
    "    df['negative_length'] = df['negative_prompt'].str.len()\n",
    "    df.query(f'positive_length < {MAX_PROMPT_LENGTH} and negative_length < {MAX_PROMPT_LENGTH}', inplace=True)\n",
    "    \n",
    "    df['positive_prompt'] = [i if (type(i) == str and max(map(len, i.split(','))) < MAX_TAG_LENGTH) else None for i in df['positive_prompt']]\n",
    "    df['negative_prompt'] = [i if (type(i) == str and max(map(len, i.split(','))) < MAX_TAG_LENGTH) else None for i in df['negative_prompt']]\n",
    "    \n",
    "    df.drop_duplicates(['positive_prompt', 'negative_prompt'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec9ad5-1e5c-4d53-9b27-391c130b201b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## extend dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f125c01a-7031-4ce3-bfe8-e8ea3605d330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_file_paths = [\n",
    "    # '../dataset/nonredundant-laion2B_aesthetic.tsv',\n",
    "    # '../dataset/nonredundant-midjourney_prompts.tsv',\n",
    "    '../dataset/nonredundant-dalle_captions.tsv',\n",
    "    '../dataset/nonredundant-dalle_chatgpt_prompts.tsv',\n",
    "    '../dataset/nonredundant-dalle_discord_prompts.tsv',\n",
    "    '../dataset/nonredundant-midjourney_prompts-paired.tsv',\n",
    "    '../dataset/long-laion2B-en-aesthetic.tsv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07b1c71-12ad-4a00-8810-d3be6336a176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = list()\n",
    "\n",
    "for file_path in prompt_file_paths:\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    prompts.append(df)\n",
    "    \n",
    "prompts = pd.concat(prompts, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d5e61f6-b9a8-4025-903f-4973785bc533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1506962/1513233826.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "preprocess(prompts)\n",
    "prompts.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e06f124-4788-4b43-8559-f0c6f324ecf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d449f09b5d49a09e09b92ec09dcd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1286753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extend_dataset = PromptDataset(prompts, tokenizer, p_shuffle=0.25, max_shuffle=2, p_cut=0.1, max_prompt_length=MAX_PROMPT_TOKEN_LENGTH, overflow_method='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad509ead-f82b-47fb-9cec-1a21623a863b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# samples = list()\n",
    "# lengths = list()\n",
    "# for tokens, is_positive in tqdm(extend_dataset.samples):\n",
    "#     length = len(tokens)\n",
    "    \n",
    "#     if length < 15:\n",
    "#         p = ((length / 25) ** 3) * 0.02\n",
    "#     elif length < 40:\n",
    "#         p = ((length - 10) / 30) ** 2 * 0.4\n",
    "\n",
    "# #     if length < 25:\n",
    "# #         p = ((length / 25) ** 2) * 0.1\n",
    "# #     elif length < 50:\n",
    "# #         p = ((length - 25) / 25) ** 0.5 * 0.5\n",
    "        \n",
    "#     else:\n",
    "#         p = 1\n",
    "#     if np.random.rand() < p:\n",
    "#         lengths.append(length)\n",
    "#         samples.append((tokens, is_positive))\n",
    "        \n",
    "# len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bb403a-11c7-4779-bb23-1f0f52fcace3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot\n",
    "# _ = pyplot.hist(lengths[::100], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3197f97-5786-48c4-8a35-90dfd178745c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sampled_aesthetic = np.array([i[0].numpy().astype('int32') for i in samples], dtype='object')\n",
    "# np.save('sampled_aesthetic.npy', sampled_aesthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c431aa7-3389-4b9c-be06-16382eccc0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sampled_midjourney = np.array([i[0].numpy().astype('int32') for i in samples], dtype='object')\n",
    "# np.save('sampled_midjourney.npy', sampled_midjourney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b45964-358b-4407-a42a-2c931f06fb24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extend_dataset.samples += [(torch.tensor(i), True) for i in np.load('../dataset/sampled_aesthetic.npy', allow_pickle=True) if len(i) < extend_dataset.max_prompt_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d2b2b1-3a4e-4c07-883a-4734c65431df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extend_dataset.samples += [(torch.tensor(i), True) for i in np.load('../dataset/sampled_midjourney.npy', allow_pickle=True) if len(i) < extend_dataset.max_prompt_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0adc9e-9691-4cb6-b27e-70e02c349b88",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bddd6de-7170-4a92-9c4c-241bfd7b88eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_file_paths = [\n",
    "    '../dataset/nonredundant-civitai_prompts.tsv',\n",
    "    '../dataset/nonredundant-discord_prompts.tsv',\n",
    "    '../dataset/nonredundant-leonardo_prompts.tsv',\n",
    "    '../dataset/nonredundant-lexica_prompts-train.tsv',\n",
    "    '../dataset/nonredundant-lexica_prompts-eval.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b3183d5-750b-4d97-9aaa-5d69473a3712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = list()\n",
    "\n",
    "for file_path in prompt_file_paths:\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    prompts.append(df)\n",
    "    \n",
    "prompts = pd.concat(prompts, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fb020a6-d390-4526-b7ba-3969598e6902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1506962/1513233826.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "preprocess(prompts)\n",
    "prompts.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f27cf991-bc5d-4891-b9fe-eb2a87723462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39529691706b4ec88ee0a0f4dcc7c57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2987064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = PromptDataset(prompts, tokenizer, p_shuffle=0.5, max_shuffle=3, p_cut=0.2, max_prompt_length=MAX_PROMPT_TOKEN_LENGTH, overflow_method='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c409b-bb8d-4d74-a1b7-17d38c32d912",
   "metadata": {},
   "source": [
    "## long dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe9637d5-e8ce-4da1-a36d-0f43f00c9d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b2b5c881354e10b7c269207eab061e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_dataset = PromptDataset(prompts.iloc[:0], tokenizer, p_shuffle=0.5, max_shuffle=3, p_cut=0., max_prompt_length=MAX_PROMPT_TOKEN_LENGTH, overflow_method='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb224f4-d406-4c63-8ef6-4844a56636cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_dataset.samples = [(p, n) for p, n in dataset.samples if p.shape[0] > MIN_LONG_PROMPT_TOKEN_LENGTH]\n",
    "long_dataset.samples = [(p, n) for p, n in extend_dataset.samples if p.shape[0] > MIN_LONG_PROMPT_TOKEN_LENGTH]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12cec78-b329-4f02-97e7-908e5321c3b8",
   "metadata": {},
   "source": [
    "## merge & split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1eb3cbfe-bfbb-4b98-a644-108072576c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3352184, 5755983, 2003619, 5755983)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = MultipleDataset([dataset, extend_dataset, long_dataset], probabilities=[0.3, 0.3, 0.4])\n",
    "len(dataset), len(extend_dataset), len(long_dataset), len(merged_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b4f2348-5217-4b3f-a826-845c34ace1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len_val_set = int(len(merged_dataset) * 0.001)\n",
    "train_set, val_set = torch.utils.data.random_split(merged_dataset, (len(merged_dataset) - len_val_set, len_val_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcbd9c-1f1c-4400-80bc-a5b97b369a39",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "339326d2-0be1-4824-82f6-2fedb7a2d4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd464e00-7428-40af-8a1e-fc347c4026a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "781e2f71-0c3e-4d81-bdbb-f6817bc181e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"GPT2-extend\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_steps=1_000,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=1e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    \n",
    "    push_to_hub=False,\n",
    "    dataloader_drop_last=True,\n",
    "    # dataloader_num_workers=8,\n",
    "    # group_by_length=True,\n",
    "    \n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1_000,\n",
    "    do_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3475dae8-26ed-45b5-8806-7fd8b65c3f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                                                                                                 \n",
    "    \n",
    "    tokenizer=dataset.tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df910c-9723-4aef-95b3-d3fb6a9b9407",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhxie/snap/kk-digital/kcg-ml-image-pipeline/venv/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/xhxie/snap/kk-digital/kcg-ml-image-pipeline/venv/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3662' max='29948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3662/29948 1:51:30 < 13:20:48, 0.55 it/s, Epoch 0.49/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.266700</td>\n",
       "      <td>2.166469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.294600</td>\n",
       "      <td>2.160431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.297300</td>\n",
       "      <td>2.174053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dff6d3-7e34-47a6-aa90-c7a67e9cfaae",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b519461-875a-44a5-a9d9-a7c011fe55bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.tokenizer.save_pretrained('weight/distilgpt2-extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c43d0-89fd-4c46-823c-5627fc3c7ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('weight/distilgpt2-extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c805a-f865-46d7-9b31-edb7327e8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752f807-73a4-4cd6-acbf-61f4d4f048b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pyplot.hist([len(train_set[i]['input_ids']) for i in range(0, len(train_set), 100)], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0275b1-63b2-412d-bb14-1eac7645da44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kk",
   "language": "python",
   "name": "kk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
